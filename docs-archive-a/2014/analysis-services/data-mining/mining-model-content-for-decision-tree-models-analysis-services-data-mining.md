---
title: 决策树模型的挖掘模型内容 (Analysis Services 数据挖掘) |Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- mining model content, decision tree models
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
ms.assetid: ac358399-10f8-4238-be32-a914a2e49048
author: minewiskan
ms.author: owend
ms.openlocfilehash: bd7c11219bd4807d019053e4100721e8cd6d658c
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 08/04/2020
ms.locfileid: "87581018"
---
# <a name="mining-model-content-for-decision-tree-models-analysis-services---data-mining"></a><span data-ttu-id="d3dd4-102">决策树模型的挖掘模型内容（Analysis Services - 数据挖掘）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-102">Mining Model Content for Decision Tree Models (Analysis Services - Data Mining)</span></span>
  <span data-ttu-id="d3dd4-103">本主题介绍使用 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法的模型特有的挖掘模型内容。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-103">This topic describes mining model content that is specific to models that use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span> <span data-ttu-id="d3dd4-104">有关所有模型类型的挖掘模型内容的常规说明，请参阅 [挖掘模型内容（Analysis Services - 数据挖掘）](mining-model-content-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-104">For a general explanation of mining model content for all model types, see [Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md).</span></span> <span data-ttu-id="d3dd4-105">请务必记住，Microsoft 决策树算法是一种混合算法，它可以创建功能相差很大的多种模型：决策树可以表示关联和规则，甚至线性回归。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-105">It is important to remember that The Microsoft Decision Trees algorithm is a hybrid algorithm that can create models with very different functions: a decision tree can represent associations, rules, or even linear regression.</span></span> <span data-ttu-id="d3dd4-106">树的结构实质上都是相同的，但如何解释信息则取决于您创建模型的目的。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-106">The structure of the tree is essentially the same, but how you interpret the information will depend on the purpose for which you created the model.</span></span>  
  
##  <a name="understanding-the-structure-of-a-decision-trees-model"></a><a name="bkmk_Top"></a><span data-ttu-id="d3dd4-107">了解决策树模型的结构</span><span class="sxs-lookup"><span data-stu-id="d3dd4-107">Understanding the Structure of a Decision Trees Model</span></span>  
 <span data-ttu-id="d3dd4-108">决策树模型具有表示该模型及其元数据的单一父节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-108">A decision trees model has a single parent node that represents the model and its metadata.</span></span> <span data-ttu-id="d3dd4-109">父节点下是表示选择的可预测属性的独立树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-109">Underneath the parent node are independent trees that represent the predictable attributes that you select.</span></span> <span data-ttu-id="d3dd4-110">例如，如果设置决策树模型以预测客户是否将购买产品，并为性别和收入提供输入，该模型将为购买属性创建一个树，该树具有大量根据性别和收入相关条件进行划分的分支。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-110">For example, if you set up your decision tree model to predict whether customers will purchase something, and provide inputs for gender and income, the model would create a single tree for the purchasing attribute, with many branches that divide on conditions related to gender and income.</span></span>  
  
 <span data-ttu-id="d3dd4-111">但是，如果随后添加一个单独的可预测属性以参与客户回报计划，该算法将在父节点下创建两个单独的树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-111">However, if you then add a separate predictable attribute for participation in a customer rewards program, the algorithm will create two separate trees under the parent node.</span></span> <span data-ttu-id="d3dd4-112">其中一个树包含购买情况分析，而另一个树包含客户回报计划的分析。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-112">One tree contains the analysis for purchasing, and another tree contains the analysis for the customer rewards program.</span></span>  <span data-ttu-id="d3dd4-113">如果使用决策树算法创建关联模型，该算法将为要预测的每个产品创建一个单独的树，而树则包含构成目标属性选择的所有其他产品组合。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-113">If you use the Decision Trees algorithm to create an association model, the algorithm creates a separate tree for each product that is being predicted, and the tree contains all the other product combinations that contribute towards selection of the target attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="d3dd4-114">如果模型包含多个树，则在 **Microsoft 树查看器**中一次只能查看一个树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-114">If your model includes multiple trees, you can view only one tree at a time in the **Microsoft Tree Viewer**.</span></span> <span data-ttu-id="d3dd4-115">但是，在 **一般内容树查看器** 中，可同时显示相同模型中的所有树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-115">However, in the **Generic Content Tree Viewer** , all trees in the same model are displayed at the same time.</span></span>  
  
 <span data-ttu-id="d3dd4-116">![决策树的模型内容结构](../media/modelcontentstructure-dt.gif "决策树的模型内容结构")</span><span class="sxs-lookup"><span data-stu-id="d3dd4-116">![structure of model content for decision tree](../media/modelcontentstructure-dt.gif "structure of model content for decision tree")</span></span>  
  
 <span data-ttu-id="d3dd4-117">每个可预测属性的树所包含的信息描述选择的输入列如何影响该特定可预测属性的结果。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-117">The tree for each predictable attribute contains information that describes how the input columns that you choose affect the outcome of that particular predictable attribute.</span></span> <span data-ttu-id="d3dd4-118">每个树以包含可预测属性的节点 (NODE_TYPE = 9) 作为开头，后跟一系列表示输入属性的节点 (NODE_TYPE = 10)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-118">Each tree is headed by a node (NODE_TYPE = 9) that contains the predictable attribute, followed by a series of nodes (NODE_TYPE = 10) that represent the input attributes.</span></span> <span data-ttu-id="d3dd4-119">属性对应于事例级列或嵌套表列的值，后者通常是嵌套表的 `Key` 列中的值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-119">An attribute corresponds to either a case-level column or values of nested table columns, which are generally the values in the `Key` column of the nested table.</span></span>  
  
 <span data-ttu-id="d3dd4-120">内部节点和叶节点表示拆分条件。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-120">Interior and leaf nodes represent split conditions.</span></span> <span data-ttu-id="d3dd4-121">树可以在相同的属性上拆分多次。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-121">A tree can split on the same attribute multiple times.</span></span> <span data-ttu-id="d3dd4-122">例如， **TM_DecisionTree** 模型可以在 [Yearly Income] 和 [Number of Children] 上拆分，继而又在 [Yearly Income] 上沿着树再次向下拆分。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-122">For example, the **TM_DecisionTree** model might split on [Yearly Income] and [Number of Children], and then split again on [Yearly Income] further down the tree.</span></span>  
  
 <span data-ttu-id="d3dd4-123">Microsoft 决策树算法还可以在整个树或部分树中包含线性回归。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-123">The Microsoft Decision Trees algorithm can also contain linear regressions in all or part of the tree.</span></span> <span data-ttu-id="d3dd4-124">如果要建模的属性是连续数值数据类型，那么，只要可以以线性方式对各属性之间的关系进行建模，该模型就可以创建回归树节点 (NODE_TYPE = 25)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-124">If the attribute that you are modeling is a continuous numeric data type, the model can create a regression tree node (NODE_TYPE = 25) wherever the relationship between the attributes can be modeled linearly.</span></span> <span data-ttu-id="d3dd4-125">在这种情况下，节点包含一个回归公式。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-125">In this case, the node contains a regression formula.</span></span>  
  
 <span data-ttu-id="d3dd4-126">但是，如果可预测属性具有离散值，或者如果数值已经过装桶或离散化处理，该模型则始终创建分类树 (NODE_TYPE =2)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-126">However, if the predictable attribute has discrete values, or if numeric values have been bucketed or discretized, the model always creates a classification tree (NODE_TYPE =2).</span></span> <span data-ttu-id="d3dd4-127">对于属性的每个值，分类树可以具有多个分支或内部树节点 (NODE_TYPE =3)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-127">A classification tree can have multiple branches or interior tree nodes (NODE_TYPE =3) for each value of the attribute.</span></span> <span data-ttu-id="d3dd4-128">但是，拆分不必基于属性的每个值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-128">However, the split is not necessarily on each value of the attribute.</span></span>  
  
 <span data-ttu-id="d3dd4-129">Microsoft 决策树算法不允许使用连续数据类型作为输入；因此，如果任何列具有连续数值数据类型，将对该值进行离散化处理。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-129">The Microsoft Decision Trees algorithm does not allow continuous data types as inputs; therefore, if any columns have a continuous numeric data type, the values are discretized.</span></span> <span data-ttu-id="d3dd4-130">该算法在拆分点针对所有连续属性执行其自己的离散化处理。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-130">The algorithm performs its own discretization at the point of a split for all continuous attributes.</span></span>  
  
> [!NOTE]  
>  [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] <span data-ttu-id="d3dd4-131">自动选择对连续属性进行装桶的方法；但是，通过将挖掘结构列的内容类型设置为 `Discretized`，并设置 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> 或 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> 属性，您可以控制如何离散化输入中的连续值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-131">automatically chooses a method for bucketing continuous attributes; however, you can control how continuous values in the inputs are discretized by setting the content type of the mining structure column to `Discretized` and then setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> or <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> property.</span></span>  
  
##  <a name="model-content-for-a-decision-trees-model"></a><a name="bkmk_ModelContent"></a> <span data-ttu-id="d3dd4-132">决策树模型的模型内容</span><span class="sxs-lookup"><span data-stu-id="d3dd4-132">Model Content for a Decision Trees Model</span></span>  
 <span data-ttu-id="d3dd4-133">本部分提供的详细信息和示例仅针对挖掘模型内容中与决策树模型有特殊关系的列。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-133">This section provides details and examples only for those columns in the mining model content that have particular relevance for decision trees models.</span></span> <span data-ttu-id="d3dd4-134">有关架构行集中的通用列的信息以及挖掘模型术语的说明，请参阅 [挖掘模型内容（Analysis Services - 数据挖掘）](mining-model-content-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-134">For information about general-purpose columns in the schema rowset, and explanations of mining model terminology, see [Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md).</span></span>  
  
 <span data-ttu-id="d3dd4-135">MODEL_CATALOG</span><span class="sxs-lookup"><span data-stu-id="d3dd4-135">MODEL_CATALOG</span></span>  
 <span data-ttu-id="d3dd4-136">存储模型的数据库的名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-136">Name of the database where the model is stored.</span></span>  
  
 <span data-ttu-id="d3dd4-137">MODEL_NAME</span><span class="sxs-lookup"><span data-stu-id="d3dd4-137">MODEL_NAME</span></span>  
 <span data-ttu-id="d3dd4-138">模型的名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-138">Name of the model.</span></span>  
  
 <span data-ttu-id="d3dd4-139">ATTRIBUTE_NAME</span><span class="sxs-lookup"><span data-stu-id="d3dd4-139">ATTRIBUTE_NAME</span></span>  
 <span data-ttu-id="d3dd4-140">与该节点相对应的属性的名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-140">Name of the attribute that corresponds to this node.</span></span>  
  
 <span data-ttu-id="d3dd4-141">NODE_NAME</span><span class="sxs-lookup"><span data-stu-id="d3dd4-141">NODE_NAME</span></span>  
 <span data-ttu-id="d3dd4-142">始终与 NODE_UNIQUE_NAME 相同。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-142">Always same as NODE_UNIQUE_NAME.</span></span>  
  
 <span data-ttu-id="d3dd4-143">NODE_UNIQUE_NAME</span><span class="sxs-lookup"><span data-stu-id="d3dd4-143">NODE_UNIQUE_NAME</span></span>  
 <span data-ttu-id="d3dd4-144">此模型中节点的唯一标识符。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-144">A unique identifier for the node within the model.</span></span> <span data-ttu-id="d3dd4-145">此值不能更改。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-145">This value cannot be changed.</span></span>  
  
 <span data-ttu-id="d3dd4-146">对于决策树模型，唯一名称遵循以下约定，该约定并不适用于所有算法：</span><span class="sxs-lookup"><span data-stu-id="d3dd4-146">For decision tree models, the unique names follow the following convention, which does not apply to all algorithms:</span></span>  
  
 <span data-ttu-id="d3dd4-147">任何特定节点的所有子节点均具有相同的十六进制前缀，后跟表示该子节点在父节点中的顺序的另一个十六进制数字。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-147">The child nodes of any particular node will all have the same hexadecimal prefix, followed by another hexadecimal number that represents the sequence of the child node within the parent.</span></span> <span data-ttu-id="d3dd4-148">使用前缀可以推断路径。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-148">You can use the prefixes to infer a path.</span></span>  
  
 <span data-ttu-id="d3dd4-149">NODE_TYPE</span><span class="sxs-lookup"><span data-stu-id="d3dd4-149">NODE_TYPE</span></span>  
 <span data-ttu-id="d3dd4-150">在决策树模型中，将创建以下类型的节点：</span><span class="sxs-lookup"><span data-stu-id="d3dd4-150">In decision tree models, the following types of nodes are created:</span></span>  
  
|<span data-ttu-id="d3dd4-151">节点类型</span><span class="sxs-lookup"><span data-stu-id="d3dd4-151">Node Type</span></span>|<span data-ttu-id="d3dd4-152">说明</span><span class="sxs-lookup"><span data-stu-id="d3dd4-152">Description</span></span>|  
|---------------|-----------------|  
|<span data-ttu-id="d3dd4-153">1（模型）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-153">1 (Model)</span></span>|<span data-ttu-id="d3dd4-154">模型的根节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-154">Root node for model.</span></span>|  
|<span data-ttu-id="d3dd4-155">2（树）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-155">2 (Tree)</span></span>|<span data-ttu-id="d3dd4-156">模型中分类树的父节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-156">Parent node for classification trees in the model.</span></span> <span data-ttu-id="d3dd4-157">标记为 **“全部”**。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-157">Labeled **"All"**.</span></span>|  
|<span data-ttu-id="d3dd4-158">3（内部）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-158">3 (Interior)</span></span>|<span data-ttu-id="d3dd4-159">内部分支的头，位于分类树或回归树中。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-159">Head of interior branch, found within in a classification tree or regression tree.</span></span>|  
|<span data-ttu-id="d3dd4-160">4（分布）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-160">4 (Distribution)</span></span>|<span data-ttu-id="d3dd4-161">叶节点，位于分类树或回归树中。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-161">Leaf node, found within a classification tree or regression tree.</span></span>|  
|<span data-ttu-id="d3dd4-162">25（回归树）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-162">25 (Regression tree)</span></span>|<span data-ttu-id="d3dd4-163">模型中回归树的父节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-163">Parent node for regression tree within the model.</span></span> <span data-ttu-id="d3dd4-164">标记为 **“全部”**。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-164">Labeled as **"All"**.</span></span>|  
  
 <span data-ttu-id="d3dd4-165">NODE_CAPTION</span><span class="sxs-lookup"><span data-stu-id="d3dd4-165">NODE_CAPTION</span></span>  
 <span data-ttu-id="d3dd4-166">显示时使用的友好名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-166">A friendly name for display purposes.</span></span>  
  
 <span data-ttu-id="d3dd4-167">当创建某个模型时，会将 NODE_UNIQUE_NAME 值自动用作标题。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-167">When you create a model, the value of NODE_UNIQUE_NAME is automatically used as the caption.</span></span> <span data-ttu-id="d3dd4-168">但是，您可以用编程方式或使用查看器更改 NODE_CAPTION 的值，以更新该分类的显示名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-168">However, you can change the value for NODE_CAPTION to update the display name for the cluster, either programmatically or by using the viewer.</span></span> <span data-ttu-id="d3dd4-169">标题由该模型自动生成。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-169">The caption is automatically generated by the model.</span></span> <span data-ttu-id="d3dd4-170">标题的内容取决于模型类型和节点类型。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-170">The content of the caption depends on the type of model, and the node type.</span></span>  
  
 <span data-ttu-id="d3dd4-171">在决策树模型中，NODE_CAPTION 和 NODE_DESCRIPTION 根据在树中的级别包含不同的信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-171">In a decision trees model, the NODE_CAPTION and the NODE_DESCRIPTION have different information, depending on the level in the tree.</span></span> <span data-ttu-id="d3dd4-172">有关详细信息和示例，请参阅 [节点标题和节点说明](#NodeCaption)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-172">For more information and examples, see [Node Caption and Node Description](#NodeCaption).</span></span>  
  
 <span data-ttu-id="d3dd4-173">CHILDREN_CARDINALITY</span><span class="sxs-lookup"><span data-stu-id="d3dd4-173">CHILDREN_CARDINALITY</span></span>  
 <span data-ttu-id="d3dd4-174">对节点所具有的子节点数的估计。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-174">An estimate of the number of children that the node has.</span></span>  
  
 <span data-ttu-id="d3dd4-175">**父节点** 指示已建模的可预测属性的数目。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-175">**Parent node** Indicates the number of predictable attributes that were modeled.</span></span> <span data-ttu-id="d3dd4-176">为每个可预测属性创建一个树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-176">A tree is created for each predictable attribute.</span></span>  
  
 <span data-ttu-id="d3dd4-177">**树节点** 每个树的 **“全部”** 节点指示用于目标属性的值的数目。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-177">**Tree node** The **All** node for each tree tells you how many values were used for the target attribute.</span></span>  
  
-   <span data-ttu-id="d3dd4-178">如果目标属性是离散属性，则该值等于非重复值的数目加 1（表示 `Missing` 状态）。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-178">If the target attribute is discrete, the value equals the number of distinct values plus 1 for the `Missing` state.</span></span>  
  
-   <span data-ttu-id="d3dd4-179">如果可预测属性是连续的，该值表示对连续属性建模所使用的存储桶数目。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-179">If the predictable attribute is continuous, the value tells you how many buckets were used to model the continuous attribute.</span></span>  
  
 <span data-ttu-id="d3dd4-180">**叶节点** 始终为 0。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-180">**Leaf nodes** Always 0.</span></span>  
  
 <span data-ttu-id="d3dd4-181">PARENT_UNIQUE_NAME</span><span class="sxs-lookup"><span data-stu-id="d3dd4-181">PARENT_UNIQUE_NAME</span></span>  
 <span data-ttu-id="d3dd4-182">节点的父节点的唯一名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-182">The unique name of the node's parent.</span></span> <span data-ttu-id="d3dd4-183">根级别上的任何节点均返回 NULL。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-183">NULL is returned for any nodes at the root level.</span></span>  
  
 <span data-ttu-id="d3dd4-184">NODE_DESCRIPTION</span><span class="sxs-lookup"><span data-stu-id="d3dd4-184">NODE_DESCRIPTION</span></span>  
 <span data-ttu-id="d3dd4-185">节点的说明。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-185">A description of the node.</span></span>  
  
 <span data-ttu-id="d3dd4-186">在决策树模型中，NODE_CAPTION 和 NODE_DESCRIPTION 根据在树中的级别包含不同的信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-186">In a decision trees model, the NODE_CAPTION and the NODE_DESCRIPTION have different information, depending on the level in the tree.</span></span>  
  
 <span data-ttu-id="d3dd4-187">有关详细信息和示例，请参阅 [节点标题和节点说明](#NodeCaption)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-187">For more information and examples, see [Node Caption and Node Description](#NodeCaption).</span></span>  
  
 <span data-ttu-id="d3dd4-188">NODE_RULE</span><span class="sxs-lookup"><span data-stu-id="d3dd4-188">NODE_RULE</span></span>  
 <span data-ttu-id="d3dd4-189">规则的 XML 说明，该规则描述了从当前节点的直接父节点到此当前节点的路径。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-189">An XML description of the rule that describes the path to the current node from its immediate parent node.</span></span>  
  
 <span data-ttu-id="d3dd4-190">有关详细信息和示例，请参阅 [节点规则和边际规则](#NodeRule)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-190">For more information and examples, see [Node Rule and Marginal Rule](#NodeRule).</span></span>  
  
 <span data-ttu-id="d3dd4-191">MARGINAL_RULE</span><span class="sxs-lookup"><span data-stu-id="d3dd4-191">MARGINAL_RULE</span></span>  
 <span data-ttu-id="d3dd4-192">规则的 XML 说明，该规则描述了从模型父节点到当前节点的路径。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-192">An XML description of the rule that describes the path from the model parent node to the current node.</span></span>  
  
 <span data-ttu-id="d3dd4-193">有关详细信息，请参阅 [节点规则和边际规则](#NodeRule)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-193">For more information, see [Node Rule and Marginal Rule](#NodeRule).</span></span>  
  
 <span data-ttu-id="d3dd4-194">NODE_PROBABILITY</span><span class="sxs-lookup"><span data-stu-id="d3dd4-194">NODE_PROBABILITY</span></span>  
 <span data-ttu-id="d3dd4-195">与此节点相关联的概率。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-195">The probability associated with this node.</span></span>  
  
 <span data-ttu-id="d3dd4-196">有关详细信息，请参阅 [概率](#bkmk_NodeDist_Discrete)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-196">For more information, see [Probability](#bkmk_NodeDist_Discrete).</span></span>  
  
 <span data-ttu-id="d3dd4-197">MARGINAL_PROBABILITY</span><span class="sxs-lookup"><span data-stu-id="d3dd4-197">MARGINAL_PROBABILITY</span></span>  
 <span data-ttu-id="d3dd4-198">从父节点到达该节点的概率。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-198">The probability of reaching the node from the parent node.</span></span>  
  
 <span data-ttu-id="d3dd4-199">有关详细信息，请参阅 [概率](#bkmk_NodeDist_Discrete)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-199">For more information, see [Probability](#bkmk_NodeDist_Discrete).</span></span>  
  
 <span data-ttu-id="d3dd4-200">NODE_DISTRIBUTION</span><span class="sxs-lookup"><span data-stu-id="d3dd4-200">NODE_DISTRIBUTION</span></span>  
 <span data-ttu-id="d3dd4-201">包含节点的概率直方图的表。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-201">A table that contains the probability histogram of the node.</span></span> <span data-ttu-id="d3dd4-202">根据可预测属性是连续变量还是离散变量，该表中的信息也将有所不同。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-202">The information in this table differs depending on whether the predictable attribute is a continuous or discrete variable.</span></span>  
  
 <span data-ttu-id="d3dd4-203">**模型根节点** 此表为空。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-203">**Model root node** This table is empty.</span></span>  
  
 <span data-ttu-id="d3dd4-204">**全部）节点** 包含整个模型的摘要。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-204">**(All) node** Contains a summary for the model as a whole.</span></span>  
  
 <span data-ttu-id="d3dd4-205">**内部节点** 包含其叶节点的聚合统计信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-205">**Interior node** Contains aggregated statistics for its leaf nodes.</span></span>  
  
 <span data-ttu-id="d3dd4-206">**叶节点** 如果在指向当前叶节点的路径中给定了所有条件，包含预测结果的支持和概率。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-206">**Leaf node** Contains support and probability for the predicted outcomes given all the conditions in the path leading to the current leaf node.</span></span>  
  
 <span data-ttu-id="d3dd4-207">**回归节点** 包含表示输入和可预测属性之间的关系的回归公式。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-207">**Regression node** Contains regression formula that represents the relationship between the inputs and the predictable attribute.</span></span>  
  
 <span data-ttu-id="d3dd4-208">有关详细信息，请参阅 [离散属性的节点分布](#bkmk_NodeDist_Discrete) 和 [连续属性的节点分布](#bkmk_RegressionNodes)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-208">For more information, see [Node Distribution for Discrete Attributes](#bkmk_NodeDist_Discrete) and [Node Distribution for Continuous Attributes](#bkmk_RegressionNodes).</span></span>  
  
 <span data-ttu-id="d3dd4-209">NODE_SUPPORT</span><span class="sxs-lookup"><span data-stu-id="d3dd4-209">NODE_SUPPORT</span></span>  
 <span data-ttu-id="d3dd4-210">支持此节点的事例的数目。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-210">The number of cases that support this node.</span></span>  
  
 <span data-ttu-id="d3dd4-211">MSOLAP_MODEL_COLUMN</span><span class="sxs-lookup"><span data-stu-id="d3dd4-211">MSOLAP_MODEL_COLUMN</span></span>  
 <span data-ttu-id="d3dd4-212">指示包含可预测属性的列。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-212">Indicates the column that contains the predictable attribute.</span></span>  
  
 <span data-ttu-id="d3dd4-213">MSOLAP_NODE_SCORE</span><span class="sxs-lookup"><span data-stu-id="d3dd4-213">MSOLAP_NODE_SCORE</span></span>  
 <span data-ttu-id="d3dd4-214">显示与此节点关联的分数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-214">Displays a score associated with the node.</span></span> <span data-ttu-id="d3dd4-215">有关详细信息，请参阅 [节点分数](#NodeScore)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-215">For more information, see [Node Score](#NodeScore).</span></span>  
  
 <span data-ttu-id="d3dd4-216">MSOLAP_NODE_SHORT_CAPTION</span><span class="sxs-lookup"><span data-stu-id="d3dd4-216">MSOLAP_NODE_SHORT_CAPTION</span></span>  
 <span data-ttu-id="d3dd4-217">用于显示的标签。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-217">A label used for display purposes.</span></span>  
  
## <a name="remarks"></a><span data-ttu-id="d3dd4-218">备注</span><span class="sxs-lookup"><span data-stu-id="d3dd4-218">Remarks</span></span>  
 <span data-ttu-id="d3dd4-219">决策树模型没有用于存储整个模型的统计信息的单独节点，这与 Naive Bayes 或神经网络模型中的边际统计信息节点不同。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-219">A decision trees model does not have a separate node that stores statistics for the entire model, unlike the marginal statistics node found in a Naive Bayes or neural network model.</span></span> <span data-ttu-id="d3dd4-220">该模型为每个可预测属性创建一个单独的树，树的顶部为“(全部)”节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-220">Instead, the model creates a separate tree for each predictable attribute, with an (All) node at the top of the tree.</span></span> <span data-ttu-id="d3dd4-221">每个树独立于其他树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-221">Each tree is independent of the others.</span></span> <span data-ttu-id="d3dd4-222">如果模型仅包含一个可预测属性，则只有一个树，因此只有一个“(全部)”节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-222">If your model contains only one predictable attribute, there is only one tree, and therefore only one (All) node.</span></span>  
  
 <span data-ttu-id="d3dd4-223">表示输出属性的每个树还进一步细分为表示拆分的内部分支 (NODE_TYPE = 3)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-223">Each tree that represents an output attribute is additionally subdivided into interior branches (NODE_TYPE = 3) that represent splits.</span></span> <span data-ttu-id="d3dd4-224">其中的每个树都包含有关目标属性的分布的统计信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-224">Each of these trees contains statistics about the distribution of the target attribute.</span></span> <span data-ttu-id="d3dd4-225">此外，每个叶节点 (NODE_TYPE = 4) 包含说明输入属性及其值以及支持每个属性值对的事例数目的统计信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-225">In addition, each leaf node (NODE_TYPE = 4) contains statistics that describe input attributes and their values, together with the number of cases in support of each attribute-value pair.</span></span> <span data-ttu-id="d3dd4-226">因此，在决策树的任何分支中，可以方便地查看数据的概率或分布，而不需要查询源数据。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-226">Therefore, in any branch of a decision tree, you can view the probabilities or the distribution of data easily without having to query the source data.</span></span> <span data-ttu-id="d3dd4-227">树的每个级别必须表示其直接子节点的总和。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-227">Each level of the tree necessarily represents the sum of its immediate child nodes.</span></span>  
  
 <span data-ttu-id="d3dd4-228">有关如何检索这些统计信息的示例，请参阅 [决策树模型查询示例](decision-trees-model-query-examples.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-228">For examples of how to retrieve these statistics, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>  
  
## <a name="example-of-decision-tree-structure"></a><span data-ttu-id="d3dd4-229">决策树结构示例：</span><span class="sxs-lookup"><span data-stu-id="d3dd4-229">Example of Decision Tree Structure</span></span>  
 <span data-ttu-id="d3dd4-230">若要了解决策树的工作原理，请设想一个示例，例如 AdventureWorks 自行车购买者方案。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-230">To understand how a decision tree works, consider an example, such as the AdventureWorks bike buyer scenario.</span></span> <span data-ttu-id="d3dd4-231">假定可预测属性是客户购买情况，决策树算法尝试在提供的所有输入中找出一列数据，该列数据可最有效地检测出可能购买和不可能购买自行车的客户。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-231">Assuming that the predictable attribute is customer purchases, the decision trees algorithm tries to find one column of data, among all the inputs that you provided, that most effectively detects the customers that are likely to purchase a bike and those who are unlikely to buy a bike.</span></span> <span data-ttu-id="d3dd4-232">例如，该模型可能会发现年龄是购买行为的最佳指标。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-232">For example, the model might find that Age is the best indicator of purchasing behavior.</span></span> <span data-ttu-id="d3dd4-233">具体来说，30 岁以上的客户很可能购买自行车，而所有其他客户则不大可能购买自行车。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-233">Specifically, that the customers over the age of 30 are very likely to purchase a bike, and all other customers are unlikely to make a purchase.</span></span> <span data-ttu-id="d3dd4-234">在这种情况下，该模型在 Age 属性上创建一个“拆分” \*\* 。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-234">In this scenario, the model creates a *split* on the Age attribute.</span></span> <span data-ttu-id="d3dd4-235">这表示树将划分成两个分支，其中一个分支包含 30 岁以上的客户，而另一个分支包含 30 岁以下的客户。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-235">That means that the tree divides into two branches, one containing customers over the age of 30, and the other containing customers under 30.</span></span> <span data-ttu-id="d3dd4-236">新分支在模型结构中表示为两个新的内部树 (NODE_TYPE = 3)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-236">The new branches are represented in the model structure as two new interior trees (NODE_TYPE = 3).</span></span>  
  
 <span data-ttu-id="d3dd4-237">对于每个分支，该模型继续查找用于区分客户的其他属性。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-237">For each branch, the model continues to look for additional attributes to use in differentiating customers.</span></span> <span data-ttu-id="d3dd4-238">如果数据中的证据不足以对客户继续创建子组，该模型则停止生成树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-238">If there is insufficient evidence in the data to continue creating subgroups of customers, the model stops building the tree.</span></span> <span data-ttu-id="d3dd4-239">当节点中的事例数太少而无法继续生成树时，该模型也会停止生成树，而不管拆分是如何的好，或者值是否为 Null 或 missing。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-239">The model will also stop building the tree whenever the number of cases in the node is too small to continue, regardless of how good the split is, or if the value is null or missing.</span></span> <span data-ttu-id="d3dd4-240">通过尽早地停止树的生长，可以防止模型被定型的与特定数据集的过度接近。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-240">By stopping the growth of the tree early, you prevent the model from training too closely to one particular set of data.</span></span>  
  
 <span data-ttu-id="d3dd4-241">每个内部树节点都包含叶节点，这些叶节点根据当前分类结果提供结果明细。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-241">Each interior tree node contains leaf nodes that provide a breakdown of the outcomes given the current classification results.</span></span> <span data-ttu-id="d3dd4-242">例如，您可能具有表示 Age >= 30 且 Gender = Male 的内部节点。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-242">For example, you might have an interior node that represents Age >= 30 and Gender = Male.</span></span> <span data-ttu-id="d3dd4-243">该组的节点显示该类别中有多少客户已购买或尚未购买产品。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-243">The node for this group shows you how many customers in this category purchased or did not purchase something.</span></span> <span data-ttu-id="d3dd4-244">例如，分类可能包含以下树拆分：</span><span class="sxs-lookup"><span data-stu-id="d3dd4-244">For example, the classification might contain the following tree splits:</span></span>  
  
|<span data-ttu-id="d3dd4-245">内部树</span><span class="sxs-lookup"><span data-stu-id="d3dd4-245">Interior tree</span></span>|<span data-ttu-id="d3dd4-246">拆分</span><span class="sxs-lookup"><span data-stu-id="d3dd4-246">Split</span></span>|  
|-------------------|-----------|  
|<span data-ttu-id="d3dd4-247">Age >= 30</span><span class="sxs-lookup"><span data-stu-id="d3dd4-247">Age >= 30</span></span>|<span data-ttu-id="d3dd4-248">Age >= 30 且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="d3dd4-248">Age >= 30 and Gender = Male</span></span>|  
||<span data-ttu-id="d3dd4-249">Age >= 30 且 Gender = Female</span><span class="sxs-lookup"><span data-stu-id="d3dd4-249">Age >= 30 and Gender = Female</span></span>|  
|<span data-ttu-id="d3dd4-250">Age < 30</span><span class="sxs-lookup"><span data-stu-id="d3dd4-250">Age < 30</span></span>|<span data-ttu-id="d3dd4-251">Age < 30 且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="d3dd4-251">Age < 30 and Gender = Male</span></span>|  
||<span data-ttu-id="d3dd4-252">年龄 \< 30 和性别 = 女性</span><span class="sxs-lookup"><span data-stu-id="d3dd4-252">Age \< 30 and Gender = Female</span></span>|  
  
 <span data-ttu-id="d3dd4-253">当使用决策树模型进行预测时，该模型将为其提供的属性用作参数，并沿着属性的路径向下通过整个树。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-253">When you use a decision tree model for prediction, the model takes the attributes that you provide to it as arguments and follows the path of the attributes down through the tree.</span></span> <span data-ttu-id="d3dd4-254">通常，所有预测都转到叶，而内部节点仅用于分类。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-254">In general, all predictions go to a leaf, and the interior nodes are used only for classification.</span></span>  
  
 <span data-ttu-id="d3dd4-255">叶节点的 NODE_TYPE 始终为 4（分布），并包含一个直方图，指示基于提供的属性的每个结果（购买或不购买）的概率。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-255">A leaf node always has a NODE_TYPE of 4 (Distribution) and contains a histogram that tells the probability of each outcome (purchase or not purchase) given the attributes you provide.</span></span> <span data-ttu-id="d3dd4-256">例如，如果您要求对一名 60 岁以上的新男性客户进行预测，该模型将查找对应的节点（Age > 30 且 Gender = Male），然后返回指定结果的概率。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-256">For example, if you ask for a prediction for a new customer who is a male over 60, the model will look up the corresponding node (Age > 30 and Gender = Male) and then return the probability for the outcome that you specify.</span></span> <span data-ttu-id="d3dd4-257">这些概率存储在节点的 [NODE_DISTRIBUTION](#bkmk_NodeDist_Discrete) 表中。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-257">These probabilities are stored in the [NODE_DISTRIBUTION](#bkmk_NodeDist_Discrete) table for the node.</span></span>  
  
 <span data-ttu-id="d3dd4-258">如果可预测属性是连续数字，该算法则尝试创建对可预测属性和输入之间的关系进行建模的回归公式。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-258">If the predictable attribute is a continuous number, the algorithm tries to create a regression formula that models the relationship between the predictable attribute and the inputs.</span></span>  
  
###  <a name="node-caption-and-node-description"></a><a name="NodeCaption"></a><span data-ttu-id="d3dd4-259">节点标题和节点说明</span><span class="sxs-lookup"><span data-stu-id="d3dd4-259">Node Caption and Node Description</span></span>  
 <span data-ttu-id="d3dd4-260">在决策树模型中，节点标题和节点说明包含类似信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-260">In a decision tree model, the node caption and node description contain similar information.</span></span> <span data-ttu-id="d3dd4-261">但是，越接近叶节点，节点说明越完整，并且包含的信息越多。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-261">However, the node description is more complete and contains more information as you move closer to the leaf nodes.</span></span> <span data-ttu-id="d3dd4-262">节点标题和节点说明是已本地化的字符串。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-262">Both the node caption and node description are localized strings.</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="d3dd4-263">**NODE_CAPTION**</span><span class="sxs-lookup"><span data-stu-id="d3dd4-263">**NODE_CAPTION**</span></span>|<span data-ttu-id="d3dd4-264">显示区分相对于父节点的特定节点的属性。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-264">Displays the attribute that distinguishes that particular node relative to the parent node.</span></span> <span data-ttu-id="d3dd4-265">节点标题基于拆分条件定义总体的子段。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-265">The node caption defines a sub-segment of the population based the split condition.</span></span> <span data-ttu-id="d3dd4-266">例如，如果 split 处于开启 [Age] 且是三向拆分，这三个子节点的节点标题可能为 "[Age] < 40"，"40 <= [Age] \< 50", "[Age] > = 50"。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-266">For example, if the split was on [Age] and it was a three-way split, the node captions for the three child nodes might be "[Age] < 40", "40 <= [Age] \< 50", "[Age] >= 50".</span></span>|  
|<span data-ttu-id="d3dd4-267">**NODE_DESCRIPTION**</span><span class="sxs-lookup"><span data-stu-id="d3dd4-267">**NODE_DESCRIPTION**</span></span>|<span data-ttu-id="d3dd4-268">包含将该节点与其他节点（从模型父节点开始）区分开来的属性的完整列表。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-268">Contains a full list of the attributes that distinguish that node from other nodes, starting from the model parent node.</span></span> <span data-ttu-id="d3dd4-269">例如，Product name = Apple 且 Color = Red。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-269">For example, Product name = Apple and Color = Red.</span></span>|  
  
###  <a name="node-rule-and-marginal-rule"></a><a name="NodeRule"></a> <span data-ttu-id="d3dd4-270">节点规则和边际规则</span><span class="sxs-lookup"><span data-stu-id="d3dd4-270">Node Rule and Marginal Rule</span></span>  
 <span data-ttu-id="d3dd4-271">NODE_RULE 和 MARGINAL_RULE 列包含的信息与 NODE_CAPTION 和 NODE_DESCRIPTION 列相同，但将这些信息表示为 XML 片段。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-271">The NODE_RULE and MARGINAL_RULE columns contain the same information as the NODE_CAPTION and NODE_DESCRIPTION columns, but represent the information as XML fragments.</span></span> <span data-ttu-id="d3dd4-272">节点规则是 XML 版本的完整路径，而边际规则指示最新拆分。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-272">The node rule is an XML version of the full path, whereas the marginal rule indicates the most recent split.</span></span>  
  
 <span data-ttu-id="d3dd4-273">XML 片段可以表示简单或复杂的属性。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-273">The attribute represented by the XML fragment can be either simple or complex.</span></span> <span data-ttu-id="d3dd4-274">简单属性包含模型列的名称以及属性的值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-274">A simple attribute contains the name of the model column, and the value of the attribute.</span></span> <span data-ttu-id="d3dd4-275">如果模型列包含嵌套表，嵌套表属性则表示为串联在一起的表名称、键值和属性。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-275">If the model column contains a nested table, the nested table attribute is represented as a concatenation of the table name, the key value, and the attribute.</span></span>  
  
> [!NOTE]  
>  [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]<span data-ttu-id="d3dd4-276">[!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)]支持版本2.0 的 PMML 标准，并带有支持嵌套表使用的扩展。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-276">[!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] supports version 2.0 of the PMML standard, with extensions to support the use of nested table.</span></span> <span data-ttu-id="d3dd4-277">如果数据包含嵌套表，并且生成 PMML 版本的模型，则模型中包括谓词的所有元素均被标记为扩展。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-277">If your data contains nested tables and you generate a PMML version of the model, all elements in the model that include the predicates are marked as an extension.</span></span>  
  
###  <a name="node-distribution-for-discrete-attributes"></a><a name="bkmk_NodeDist_Discrete"></a><span data-ttu-id="d3dd4-278">离散属性的节点分布</span><span class="sxs-lookup"><span data-stu-id="d3dd4-278">Node Distribution for Discrete Attributes</span></span>  
 <span data-ttu-id="d3dd4-279">在决策树模型中，NODE_DISTRIBUTION 表包含有用的统计信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-279">In a decision trees model, the NODE_DISTRIBUTION table contains useful statistics.</span></span> <span data-ttu-id="d3dd4-280">但是，统计信息的类型取决于树是预测离散属性还是预测连续属性。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-280">However, the type of statistics depends on whether the tree predicts a discrete or continuous attribute.</span></span> <span data-ttu-id="d3dd4-281">此部分说明离散属性的节点分布统计信息的含义。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-281">This section describes the meaning of the node distribution statistics for discrete attributes.</span></span>  
  
#### <a name="attribute-name-and-attribute-value"></a><span data-ttu-id="d3dd4-282">属性名称和属性值</span><span class="sxs-lookup"><span data-stu-id="d3dd4-282">Attribute Name and Attribute Value</span></span>  
 <span data-ttu-id="d3dd4-283">在分类树中，属性名称始终包含可预测列的名称。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-283">In a classification tree, the attribute name always contains the name of the predictable column.</span></span> <span data-ttu-id="d3dd4-284">该值指示树预测的内容。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-284">This value tells you what the tree predicts.</span></span> <span data-ttu-id="d3dd4-285">由于单个树始终表示单个可预测属性，因此该值在整个树中重复。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-285">Because a single tree always represents a single predictable attribute, this value is repeated throughout the tree.</span></span>  
  
 <span data-ttu-id="d3dd4-286">对于离散数据类型，属性值字段列出可预测列的可能值以及 `Missing` 值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-286">For a discrete data type, the attribute value field lists the possible values of the predictable column, plus the `Missing` value.</span></span>  
  
#### <a name="support"></a><span data-ttu-id="d3dd4-287">支持</span><span class="sxs-lookup"><span data-stu-id="d3dd4-287">Support</span></span>  
 <span data-ttu-id="d3dd4-288">每个节点的支持值指示该节点包括的事例数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-288">The support value for each node tells you how many cases are included in this node.</span></span> <span data-ttu-id="d3dd4-289">在“(全部)”级别，将显示用于定型模型的事例的完整计数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-289">At the (All) level, you should see the complete count of cases that were used to train the model.</span></span> <span data-ttu-id="d3dd4-290">对于树中的每个拆分，支持值是分组到树的该节点中的事例计数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-290">For each split in the tree, the support value is the count of cases that were grouped into that node of the tree.</span></span> <span data-ttu-id="d3dd4-291">叶节点中的事例总和必须等于树的父节点中的事例计数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-291">The sum of cases in the leaf nodes necessarily equals the count of cases in the parent node of the tree.</span></span>  
  
 <span data-ttu-id="d3dd4-292">对于表示连续属性的节点，数据中存在 Null 值可能产生某些不够直观的结果。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-292">For nodes that represent continuous attributes, the presence of nulls in the data might lead to some counterintuitive results.</span></span> <span data-ttu-id="d3dd4-293">例如，如果存在 m 个事例，平均值则计为 sum(all cases)/n，其中 n 是小于 m 的数字，m-n 则为 Missing 值的事例的计数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-293">For example, if there are m cases, a mean value would be calculated as sum(all cases)/n, where n is a number less than m, and m-n indicates the count of cases with missing values.</span></span> <span data-ttu-id="d3dd4-294">支持也表示为 n。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-294">Support is also represented as n.</span></span>  
  
#### <a name="probability"></a><span data-ttu-id="d3dd4-295">概率</span><span class="sxs-lookup"><span data-stu-id="d3dd4-295">Probability</span></span>  
 <span data-ttu-id="d3dd4-296">与每个节点关联的概率指示整个数据集中的任一事例终结于该特定节点的概率。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-296">The probability associated with each node tells you the probability that any case in the whole data set would end up in this particular node.</span></span> <span data-ttu-id="d3dd4-297">将针对整个树和直接拆分计算概率分数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-297">Probability scores are computed both for the tree as a whole, and for the immediate split.</span></span>  
  
 <span data-ttu-id="d3dd4-298">例如，下表显示了一个具有 100 个事例的非常简单的模型。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-298">For example, the following table shows a very simple model, with 100 cases.</span></span>  
  
|<span data-ttu-id="d3dd4-299">内部树</span><span class="sxs-lookup"><span data-stu-id="d3dd4-299">Interior tree</span></span>|<span data-ttu-id="d3dd4-300">案例</span><span class="sxs-lookup"><span data-stu-id="d3dd4-300">Cases</span></span>|<span data-ttu-id="d3dd4-301">叶节点</span><span class="sxs-lookup"><span data-stu-id="d3dd4-301">Leaf node</span></span>|<span data-ttu-id="d3dd4-302">案例</span><span class="sxs-lookup"><span data-stu-id="d3dd4-302">Cases</span></span>|<span data-ttu-id="d3dd4-303">相对于父节点的概率</span><span class="sxs-lookup"><span data-stu-id="d3dd4-303">Probability relative to parent node</span></span>|<span data-ttu-id="d3dd4-304">相对于顶端节点的概率</span><span class="sxs-lookup"><span data-stu-id="d3dd4-304">Probability relative to top node</span></span>|  
|-------------------|-----------|---------------|-----------|-----------------------------------------|--------------------------------------|  
|<span data-ttu-id="d3dd4-305">Age >= 30</span><span class="sxs-lookup"><span data-stu-id="d3dd4-305">Age >= 30</span></span>|<span data-ttu-id="d3dd4-306">60</span><span class="sxs-lookup"><span data-stu-id="d3dd4-306">60</span></span>|<span data-ttu-id="d3dd4-307">Age >= 30 且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="d3dd4-307">Age >= 30 and Gender = Male</span></span>|<span data-ttu-id="d3dd4-308">50</span><span class="sxs-lookup"><span data-stu-id="d3dd4-308">50</span></span>|<span data-ttu-id="d3dd4-309">50/60 = .83</span><span class="sxs-lookup"><span data-stu-id="d3dd4-309">50/60 = .83</span></span>|<span data-ttu-id="d3dd4-310">50/100 = .5</span><span class="sxs-lookup"><span data-stu-id="d3dd4-310">50/100 = .5</span></span>|  
|||<span data-ttu-id="d3dd4-311">Age >= 30 且 Gender = Female</span><span class="sxs-lookup"><span data-stu-id="d3dd4-311">Age >= 30 and Gender = Female</span></span>|<span data-ttu-id="d3dd4-312">10</span><span class="sxs-lookup"><span data-stu-id="d3dd4-312">10</span></span>|<span data-ttu-id="d3dd4-313">10/60 = .16</span><span class="sxs-lookup"><span data-stu-id="d3dd4-313">10/60 = .16</span></span>|<span data-ttu-id="d3dd4-314">10/100 = .10</span><span class="sxs-lookup"><span data-stu-id="d3dd4-314">10/100 = .10</span></span>|  
|<span data-ttu-id="d3dd4-315">Age < 30</span><span class="sxs-lookup"><span data-stu-id="d3dd4-315">Age < 30</span></span>|<span data-ttu-id="d3dd4-316">40</span><span class="sxs-lookup"><span data-stu-id="d3dd4-316">40</span></span>|<span data-ttu-id="d3dd4-317">Age < 30 且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="d3dd4-317">Age < 30 and Gender = Male</span></span>|<span data-ttu-id="d3dd4-318">30</span><span class="sxs-lookup"><span data-stu-id="d3dd4-318">30</span></span>|<span data-ttu-id="d3dd4-319">30/40 = .75</span><span class="sxs-lookup"><span data-stu-id="d3dd4-319">30/40 = .75</span></span>|<span data-ttu-id="d3dd4-320">30/100 = .30</span><span class="sxs-lookup"><span data-stu-id="d3dd4-320">30/100 = .30</span></span>|  
|||<span data-ttu-id="d3dd4-321">Age < 30 且 Gender = Female</span><span class="sxs-lookup"><span data-stu-id="d3dd4-321">Age < 30 and Gender = Female</span></span>|<span data-ttu-id="d3dd4-322">10</span><span class="sxs-lookup"><span data-stu-id="d3dd4-322">10</span></span>|<span data-ttu-id="d3dd4-323">10/40 = .25</span><span class="sxs-lookup"><span data-stu-id="d3dd4-323">10/40 = .25</span></span>|<span data-ttu-id="d3dd4-324">10/100 = .10</span><span class="sxs-lookup"><span data-stu-id="d3dd4-324">10/100 = .10</span></span>|  
  
 <span data-ttu-id="d3dd4-325">在所有模型中进行小幅调整，以便将可能的 Missing 值的情况考虑在内。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-325">A small adjustment is made in all models to account for possible missing values.</span></span> <span data-ttu-id="d3dd4-326">对于连续属性，每个值或值的范围都表示为状态 (例如，年龄 \<30, Age = 30, and Age > 30) ，概率按如下方式计算：状态存在 (value = 1) ，值 = 0 (，状态为 `Missing` 。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-326">For continuous attributes, each value or range of values is represented as a state (for example, Age \<30, Age = 30, and Age >30) and the probabilities are calculated as follows: state exists (value = 1), some other state exists (value = 0), state is `Missing`.</span></span> <span data-ttu-id="d3dd4-327">有关如何调整概率以表示 Missing 值的详细信息，请参阅[缺失值（Analysis Services - 数据挖掘）](missing-values-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-327">For more information about how probabilities are adjusted to represent missing values, see [Missing Values &#40;Analysis Services - Data Mining&#41;](missing-values-analysis-services-data-mining.md).</span></span>  
  
 <span data-ttu-id="d3dd4-328">每个节点的概率几乎是通过分布情况直接计算出的，如下所示：</span><span class="sxs-lookup"><span data-stu-id="d3dd4-328">The probabilities for each node are calculated almost directly from the distribution, as follows:</span></span>  
  
 <span data-ttu-id="d3dd4-329">概率 =（对状态的支持 + 对先前状态的支持）/（节点支持加上对先前节点的支持）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-329">Probability = (support for state + support for prior state) / (node support plus the prior node support)</span></span>  
  
 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] <span data-ttu-id="d3dd4-330">使用每个节点的概率比较存储概率和以前的概率，以便确定从父节点到子节点的路径是否指示较强的推断。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-330">uses probabilities for each node to compare the stored probability with the prior probability to determine whether the path from the parent to the child node indicates a strong inference.</span></span>  
  
 <span data-ttu-id="d3dd4-331">作出预测时，必须使用节点的概率平衡分布的概率，从而使概率平滑。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-331">When making predictions, the probability of the distribution must be balanced with the probability of the node, to smoothen the probabilities.</span></span> <span data-ttu-id="d3dd4-332">例如，如果树中的拆分按 9000/1000 的比率分隔事例，则该树很不平衡。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-332">For example, if a split in the tree separates cases by a ratio of 9000/1000, the tree is very unbalanced.</span></span> <span data-ttu-id="d3dd4-333">这会导致来自较小分支的预测和来自含有多个事例的分支的预测具有不同的权重。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-333">As a result, a prediction coming from the small branch should not carry the same weight as a prediction coming from a branch with many cases.</span></span>  
  
#### <a name="variance"></a><span data-ttu-id="d3dd4-334">Variance</span><span class="sxs-lookup"><span data-stu-id="d3dd4-334">Variance</span></span>  
 <span data-ttu-id="d3dd4-335">方差是在给定预期分布中，示例中的值的偏离程度的度量值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-335">Variance is a measure of how scattered values in a sample are, given an expected distribution.</span></span> <span data-ttu-id="d3dd4-336">对于离散值，根据定义方差为 0。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-336">For discrete values, the variance is 0 by definition.</span></span>  
  
 <span data-ttu-id="d3dd4-337">有关如何计算连续值的方差的详细信息，请参阅[线性回归模型的挖掘模型内容（Analysis Services - 数据挖掘）](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-337">For information about how variance is calculated for continuous values, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
#### <a name="value-type"></a><span data-ttu-id="d3dd4-338">值类型</span><span class="sxs-lookup"><span data-stu-id="d3dd4-338">Value Type</span></span>  
 <span data-ttu-id="d3dd4-339">值类型列提供在 NODE_DISTRIBUTION 表的其他列中提供的数值的含义的相关信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-339">The value type column provides information about the meaning of the numeric value provided in the other columns in the NODE_DISTRIBUTION table.</span></span> <span data-ttu-id="d3dd4-340">您可以在查询中使用值类型，以便检索嵌套表的特定行。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-340">You can use the value type in queries to retrieve specific rows from the nested tables.</span></span> <span data-ttu-id="d3dd4-341">有关示例，请参阅 [决策树模型查询示例](decision-trees-model-query-examples.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-341">For examples, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>  
  
 <span data-ttu-id="d3dd4-342">对于 <xref:Microsoft.AnalysisServices.AdomdClient.MiningValueType> 枚举中的类型，在分类树中使用以下类型。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-342">Of the types in the <xref:Microsoft.AnalysisServices.AdomdClient.MiningValueType> enumeration, the following are used in classification trees.</span></span>  
  
|<span data-ttu-id="d3dd4-343">值类型</span><span class="sxs-lookup"><span data-stu-id="d3dd4-343">Value type</span></span>|<span data-ttu-id="d3dd4-344">说明</span><span class="sxs-lookup"><span data-stu-id="d3dd4-344">Description</span></span>|  
|----------------|-----------------|  
|<span data-ttu-id="d3dd4-345">1（缺失）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-345">1 (Missing)</span></span>|<span data-ttu-id="d3dd4-346">指示与 Missing 值相关的计数、概率或其他统计信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-346">Indicates a count, probability, or other statistic related to missing values.</span></span>|  
|<span data-ttu-id="d3dd4-347">4（离散）</span><span class="sxs-lookup"><span data-stu-id="d3dd4-347">4 (Discrete)</span></span>|<span data-ttu-id="d3dd4-348">指示与离散或离散化值相关的计数、概率或其他统计信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-348">Indicates a count, probability, or other statistic related to a discrete or discretized value.</span></span>|  
  
 <span data-ttu-id="d3dd4-349">如果该模型包含连续可预测属性，树还可以包含回归公式独有的值类型。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-349">If the model includes a continuous predictable attribute, the tree might also contain value types that are unique to regression formulas.</span></span> <span data-ttu-id="d3dd4-350">有关在回归树中使用的值类型的列表，请参阅[线性回归模型的挖掘模型内容（Analysis Services - 数据挖掘）](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-350">For a list of the value types that are used in regression trees, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
###  <a name="node-score"></a><a name="NodeScore"></a> <span data-ttu-id="d3dd4-351">节点分数</span><span class="sxs-lookup"><span data-stu-id="d3dd4-351">Node Score</span></span>  
 <span data-ttu-id="d3dd4-352">节点分数表示树的每个级别的稍有不同的信息。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-352">The node score represents slightly different information at each level of the tree.</span></span> <span data-ttu-id="d3dd4-353">通常，分数是指示基于条件进行拆分的拆分性能的数值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-353">In general, the score is a numeric value that tells you how good a split was achieved by splitting on the condition.</span></span> <span data-ttu-id="d3dd4-354">该值表示为一个双精度值，值越大，性能越好。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-354">The value is represented as a double, where a higher value is better.</span></span>  
  
 <span data-ttu-id="d3dd4-355">根据定义，模型节点和所有叶节点的节点分数为 0。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-355">By definition, the model node and all leaf nodes have a node score of 0.</span></span>  
  
 <span data-ttu-id="d3dd4-356">对于表示每个树的顶部的“(全部)”节点，MSOLAP_NODE_SCORE 列包含整个树中的最佳拆分分数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-356">For the (All) node that represents the top of each tree, the MSOLAP_NODE_SCORE column contains the best split score in the whole tree.</span></span>  
  
 <span data-ttu-id="d3dd4-357">对于树中的所有其他节点（叶节点除外），每个节点的分数表示当前节点的最佳拆分分数减去父节点的拆分分数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-357">For all other nodes in the tree (except leaf nodes), the score for each node represents the best split score for the current node, minus the split score for the parent node.</span></span> <span data-ttu-id="d3dd4-358">通常，父节点的拆分分数应始终优于其任一子节点的拆分分数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-358">Typically, the split score for a parent node should always be better than the split score on any one of its child nodes.</span></span> <span data-ttu-id="d3dd4-359">这是因为在理想情况下，决策树模型首先在最重要的属性上拆分。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-359">That is because a decision trees model ideally splits on the most important attributes first.</span></span>  
  
 <span data-ttu-id="d3dd4-360">有多种方式计算拆分分数，具体选择哪种方式取决于您选择的算法参数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-360">There are many ways of calculating a score for a split, depending on the algorithm parameter you choose.</span></span> <span data-ttu-id="d3dd4-361">有关如何针对每种评分方法计算分数的讨论不属于本主题的讨论范围。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-361">A discussion of how the scores are calculated for each of the scoring methods is beyond the scope of this topic.</span></span> <span data-ttu-id="d3dd4-362">有关详细信息，请参阅[研究网站上的“](https://go.microsoft.com/fwlink/?LinkId=45963)Learning Bayesian Networks: The Combination of Knowledge and Statistical Data [!INCLUDE[msCoName](../../includes/msconame-md.md)] ”（了解 Bayesian 网络：知识与统计数据的组合）。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-362">For more information, see "[Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963)", on the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Research Web site.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="d3dd4-363">如果创建的决策树模型同时具有连续可预测属性和离散可预测属性，表示每个树类型的“(全部)”节点中将显示完全不同的分数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-363">If you create a decision trees model that has both continuous and discrete predictable attributes, you will see completely different scores in the (All) nodes that represent each tree type.</span></span> <span data-ttu-id="d3dd4-364">应单独考虑每个模型，并且对回归评分所使用的方法完全不同于对分类评分所使用的方法。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-364">Each model should be considered independently, and the methods used for scoring regression are completely different from those used for scoring classification.</span></span> <span data-ttu-id="d3dd4-365">无法比较节点分数值。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-365">The node score values cannot be compared.</span></span>  
  
##  <a name="regression-nodes-within-a-decision-tree-model"></a><a name="bkmk_RegressionNodes"></a><span data-ttu-id="d3dd4-366">决策树模型中的回归节点</span><span class="sxs-lookup"><span data-stu-id="d3dd4-366">Regression Nodes within a Decision Tree Model</span></span>  
 <span data-ttu-id="d3dd4-367">如果决策树模型包含带有连续数值数据的可预测属性，则 Microsoft 决策树算法查找被预测状态和输入变量之间存在线性关系的区域。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-367">If a decision trees model contains a predictable attribute with continuous numeric data, the Microsoft Decision Trees algorithm seeks to find areas in the data where the relationship between the predicted state and the input variables is linear.</span></span> <span data-ttu-id="d3dd4-368">如果算法成功找到线性关系，则将创建表示线性回归的特殊树 (NODE_TYPE = 25)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-368">If the algorithm is successful in finding a linear relationship, it creates a special tree (NODE_TYPE = 25) that represents a linear regression.</span></span> <span data-ttu-id="d3dd4-369">这些回归树节点比表示离散值的节点更复杂。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-369">These regression tree nodes are more complex than nodes that represent discrete values.</span></span>  
  
 <span data-ttu-id="d3dd4-370">通常，回归映射连续依赖项（可预测变量）中的更改作为输入中的更改函数。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-370">In general, a regression maps the changes in the continuous dependent (predictable variable) as a function of changes in the inputs.</span></span> <span data-ttu-id="d3dd4-371">如果依赖变量具有任何连续输入，并且输入和预测值之间的关系非常稳定，足以将其作为线形图计算，那么，回归节点则包含一个公式。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-371">If the dependent variable has any continuous inputs, and the relationship between the input and predicted value is stable enough to be computed as a line graph, the node for the regression contains a formula.</span></span>  
  
 <span data-ttu-id="d3dd4-372">但是，如果输入和预测值之间是“非线性” \*\* 关系，则转而创建拆分，这与标准决策树类似。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-372">However, if the relationship between the input and predicted value is *nonlinear*, a split is created instead, just like a standard decision tree.</span></span> <span data-ttu-id="d3dd4-373">例如，假定 A 是可预测属性，B 和 C 是输入，其中 C 是连续值类型。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-373">For example, assume that A is the predictable attribute, and B and C are the inputs, where C is a continuous value type.</span></span> <span data-ttu-id="d3dd4-374">如果 A 和 C 之间的关系在部分数据中相当稳定，而在其他数据中不稳定，该算法将创建拆分以便表示数据的不同区域。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-374">If the relationship between A and C is fairly stable in parts of the data, but unstable in others, the algorithm will create splits to represent the different areas of the data.</span></span>  
  
|<span data-ttu-id="d3dd4-375">拆分条件</span><span class="sxs-lookup"><span data-stu-id="d3dd4-375">Split condition</span></span>|<span data-ttu-id="d3dd4-376">节点结果</span><span class="sxs-lookup"><span data-stu-id="d3dd4-376">Result in node</span></span>|  
|---------------------|--------------------|  
|<span data-ttu-id="d3dd4-377">如果 n \< 5</span><span class="sxs-lookup"><span data-stu-id="d3dd4-377">if n \< 5</span></span>|<span data-ttu-id="d3dd4-378">关系可以以公式 1 表示</span><span class="sxs-lookup"><span data-stu-id="d3dd4-378">Relationship can be expressed as equation 1</span></span>|  
|<span data-ttu-id="d3dd4-379">如果 n 介于 5 和 10 之间</span><span class="sxs-lookup"><span data-stu-id="d3dd4-379">if n between 5 and 10</span></span>|<span data-ttu-id="d3dd4-380">无公式</span><span class="sxs-lookup"><span data-stu-id="d3dd4-380">No equation</span></span>|  
|<span data-ttu-id="d3dd4-381">如果 n > 10</span><span class="sxs-lookup"><span data-stu-id="d3dd4-381">if n > 10</span></span>|<span data-ttu-id="d3dd4-382">关系可以以公式 2 表示</span><span class="sxs-lookup"><span data-stu-id="d3dd4-382">Relationship can be expressed as equation 2</span></span>|  
  
 <span data-ttu-id="d3dd4-383">有关回归节点的详细信息，请参阅[线性回归模型的挖掘模型内容（Analysis Services - 数据挖掘）](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d3dd4-383">For more information about regression nodes, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="d3dd4-384">另请参阅</span><span class="sxs-lookup"><span data-stu-id="d3dd4-384">See Also</span></span>  
 <span data-ttu-id="d3dd4-385">[挖掘模型内容 &#40;Analysis Services 数据挖掘&#41;](mining-model-content-analysis-services-data-mining.md) </span><span class="sxs-lookup"><span data-stu-id="d3dd4-385">[Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md) </span></span>  
 <span data-ttu-id="d3dd4-386">[数据挖掘模型查看器](data-mining-model-viewers.md) </span><span class="sxs-lookup"><span data-stu-id="d3dd4-386">[Data Mining Model Viewers](data-mining-model-viewers.md) </span></span>  
 <span data-ttu-id="d3dd4-387">[数据挖掘查询](data-mining-queries.md) </span><span class="sxs-lookup"><span data-stu-id="d3dd4-387">[Data Mining Queries](data-mining-queries.md) </span></span>  
 [<span data-ttu-id="d3dd4-388">Microsoft 决策树算法</span><span class="sxs-lookup"><span data-stu-id="d3dd4-388">Microsoft Decision Trees Algorithm</span></span>](microsoft-decision-trees-algorithm.md)  
  
  
