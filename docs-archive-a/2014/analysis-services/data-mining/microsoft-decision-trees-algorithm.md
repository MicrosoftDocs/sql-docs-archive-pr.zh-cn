---
title: Microsoft 决策树算法 |Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- predictions [Analysis Services], discrete attributes
- predictions [Analysis Services], continuous attributes
- algorithms [data mining]
- discrete attributes [Analysis Services]
- classification algorithms [Analysis Services]
- discrete columns [Analysis Services]
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- continuous columns
- regression algorithms [Analysis Services]
ms.assetid: 95ffe66f-c261-4dc5-ad57-14d2d73205ff
author: minewiskan
ms.author: owend
ms.openlocfilehash: 3c9a893a6f0cb02e5acd2e497e0b57c29d7ac2ca
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 08/04/2020
ms.locfileid: "87588137"
---
# <a name="microsoft-decision-trees-algorithm"></a><span data-ttu-id="d44b5-102">Microsoft 决策树算法</span><span class="sxs-lookup"><span data-stu-id="d44b5-102">Microsoft Decision Trees Algorithm</span></span>
  <span data-ttu-id="d44b5-103">[!INCLUDE[msCoName](../../includes/msconame-md.md)]决策树算法是提供的一种分类和回归算法， [!INCLUDE[msCoName](../../includes/msconame-md.md)] [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] 用于对离散属性和连续属性进行预测性建模。</span><span class="sxs-lookup"><span data-stu-id="d44b5-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a classification and regression algorithm provided by [!INCLUDE[msCoName](../../includes/msconame-md.md)] [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] for use in predictive modeling of both discrete and continuous attributes.</span></span>

 <span data-ttu-id="d44b5-104">对于离散属性，该算法根据数据集中输入列之间的关系进行预测。</span><span class="sxs-lookup"><span data-stu-id="d44b5-104">For discrete attributes, the algorithm makes predictions based on the relationships between input columns in a dataset.</span></span> <span data-ttu-id="d44b5-105">它使用这些列的值（也称之为状态）预测指定为可预测的列的状态。</span><span class="sxs-lookup"><span data-stu-id="d44b5-105">It uses the values, known as states, of those columns to predict the states of a column that you designate as predictable.</span></span> <span data-ttu-id="d44b5-106">具体地说，该算法标识与可预测列相关的输入列。</span><span class="sxs-lookup"><span data-stu-id="d44b5-106">Specifically, the algorithm identifies the input columns that are correlated with the predictable column.</span></span> <span data-ttu-id="d44b5-107">例如，在预测哪些客户可能购买自行车的方案中，假如在十名年轻客户中有九名购买了自行车，但在十名年龄较大的客户中只有两名购买了自行车，则该算法从中推断出年龄是自行车购买情况的最佳预测因子。</span><span class="sxs-lookup"><span data-stu-id="d44b5-107">For example, in a scenario to predict which customers are likely to purchase a bicycle, if nine out of ten younger customers buy a bicycle, but only two out of ten older customers do so, the algorithm infers that age is a good predictor of bicycle purchase.</span></span> <span data-ttu-id="d44b5-108">决策树根据朝向特定结果发展的趋势进行预测。</span><span class="sxs-lookup"><span data-stu-id="d44b5-108">The decision tree makes predictions based on this tendency toward a particular outcome.</span></span>

 <span data-ttu-id="d44b5-109">对于连续属性，该算法使用线性回归确定决策树的拆分位置。</span><span class="sxs-lookup"><span data-stu-id="d44b5-109">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>

 <span data-ttu-id="d44b5-110">如果将多个列设置为可预测列，或输入数据中包含设置为可预测的嵌套表，则该算法将为每个可预测列生成一个单独的决策树。</span><span class="sxs-lookup"><span data-stu-id="d44b5-110">If more than one column is set to predictable, or if the input data contains a nested table that is set to predictable, the algorithm builds a separate decision tree for each predictable column</span></span>

## <a name="example"></a><span data-ttu-id="d44b5-111">示例</span><span class="sxs-lookup"><span data-stu-id="d44b5-111">Example</span></span>
 <span data-ttu-id="d44b5-112">[!INCLUDE[ssSampleDBCoFull](../../includes/sssampledbcofull-md.md)] 公司的市场部希望标识以前的客户的某些特征，这些特征可能指示这些客户将来是否有可能购买其产品。</span><span class="sxs-lookup"><span data-stu-id="d44b5-112">The marketing department of the [!INCLUDE[ssSampleDBCoFull](../../includes/sssampledbcofull-md.md)] company wants to identify the characteristics of previous customers that might indicate whether those customers are likely to buy a product in the future.</span></span> <span data-ttu-id="d44b5-113">[!INCLUDE[ssSampleDBnormal](../../includes/sssampledbnormal-md.md)] 数据库存储描述其以前客户的人口统计信息。</span><span class="sxs-lookup"><span data-stu-id="d44b5-113">The [!INCLUDE[ssSampleDBnormal](../../includes/sssampledbnormal-md.md)] database stores demographic information that describes previous customers.</span></span> <span data-ttu-id="d44b5-114">通过使用 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法分析这些信息，市场部可以生成一个模型，该模型根据有关特定客户的已知列的状态（如人口统计或以前的购买模式）预测该客户是否会购买产品。</span><span class="sxs-lookup"><span data-stu-id="d44b5-114">By using the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm to analyze this information, the marketing department can build a model that predicts whether a particular customer will purchase products, based on the states of known columns about that customer, such as demographics or past buying patterns.</span></span>

## <a name="how-the-algorithm-works"></a><span data-ttu-id="d44b5-115">算法的原理</span><span class="sxs-lookup"><span data-stu-id="d44b5-115">How the Algorithm Works</span></span>
 <span data-ttu-id="d44b5-116">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法通过在树中创建一系列拆分来生成数据挖掘模型。</span><span class="sxs-lookup"><span data-stu-id="d44b5-116">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm builds a data mining model by creating a series of splits in the tree.</span></span> <span data-ttu-id="d44b5-117">这些拆分以“ \*\* 节点”来表示。</span><span class="sxs-lookup"><span data-stu-id="d44b5-117">These splits are represented as *nodes*.</span></span> <span data-ttu-id="d44b5-118">每当发现输入列与可预测列密切相关时，该算法便会向该模型中添加一个节点。</span><span class="sxs-lookup"><span data-stu-id="d44b5-118">The algorithm adds a node to the model every time that an input column is found to be significantly correlated with the predictable column.</span></span> <span data-ttu-id="d44b5-119">该算法确定拆分的方式不同，主要取决于它预测的是连续列还是离散列。</span><span class="sxs-lookup"><span data-stu-id="d44b5-119">The way that the algorithm determines a split is different depending on whether it is predicting a continuous column or a discrete column.</span></span>

 <span data-ttu-id="d44b5-120">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法使用“ \*\* 功能选择”来指导如何选择最有用的属性。</span><span class="sxs-lookup"><span data-stu-id="d44b5-120">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm uses *feature selection* to guide the selection of the most useful attributes.</span></span> <span data-ttu-id="d44b5-121">所有 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] 数据挖掘算法均使用功能选择来改善分析的性能和质量。</span><span class="sxs-lookup"><span data-stu-id="d44b5-121">Feature selection is used by all [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms to improve performance and the quality of analysis.</span></span> <span data-ttu-id="d44b5-122">功能选择对防止不重要的属性占用处理器时间意义重大。</span><span class="sxs-lookup"><span data-stu-id="d44b5-122">Feature selection is important to prevent unimportant attributes from using processor time.</span></span> <span data-ttu-id="d44b5-123">如果在设计数据挖掘模型时使用过多的输入或可预测属性，则可能需要很长的时间来处理该模型，甚至导致内存不足。</span><span class="sxs-lookup"><span data-stu-id="d44b5-123">If you use too many input or predictable attributes when you design a data mining model, the model can take a very long time to process, or even run out of memory.</span></span> <span data-ttu-id="d44b5-124">用于确定是否拆分树的方法包括“平均信息量”\*\* 和 Bayesian 网络的行业标准度量。\*\*</span><span class="sxs-lookup"><span data-stu-id="d44b5-124">Methods used to determine whether to split the tree include industry-standard metrics for *entropy* and Bayesian networks *.*</span></span> <span data-ttu-id="d44b5-125">有关用于选择有意义的属性以及对这些属性计分和排列的方法的详细信息，请参阅[功能选择（数据挖掘）](feature-selection-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-125">For more information about the methods used to select meaningful attributes and then score and rank the attributes, see [Feature Selection &#40;Data Mining&#41;](feature-selection-data-mining.md).</span></span>

 <span data-ttu-id="d44b5-126">数据挖掘模型中的一个常见问题是该模型对定型数据中的细微差异过于敏感，在这种情况下，它会被*过度拟合*或*过度定型*。</span><span class="sxs-lookup"><span data-stu-id="d44b5-126">A common problem in data mining models is that the model becomes too sensitive to small differences in the training data, in which case it said to be *over-fitted* or *over-trained*.</span></span> <span data-ttu-id="d44b5-127">过度拟合模型无法推广到其他数据集。</span><span class="sxs-lookup"><span data-stu-id="d44b5-127">An overfitted model cannot be generalized to other data sets.</span></span> <span data-ttu-id="d44b5-128">为避免模型对任何特定的数据集过度拟合， [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法使用一些技术来控制树的生长。</span><span class="sxs-lookup"><span data-stu-id="d44b5-128">To avoid overfitting on any particular set of data, the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm uses techniques for controlling the growth of the tree.</span></span> <span data-ttu-id="d44b5-129">有关 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法工作方式的更深入说明，请参阅 [Microsoft 决策树算法技术参考](microsoft-decision-trees-algorithm-technical-reference.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-129">For a more in-depth explanation of how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works, see [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md).</span></span>

### <a name="predicting-discrete-columns"></a><span data-ttu-id="d44b5-130">预测离散列</span><span class="sxs-lookup"><span data-stu-id="d44b5-130">Predicting Discrete Columns</span></span>
 <span data-ttu-id="d44b5-131">通过柱状图可以演示 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法为可预测的离散列生成树的方式。</span><span class="sxs-lookup"><span data-stu-id="d44b5-131">The way that the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm builds a tree for a discrete predictable column can be demonstrated by using a histogram.</span></span> <span data-ttu-id="d44b5-132">下面的关系图显示了一个根据输入列 Age 绘出可预测列 Bike Buyers 的柱状图。</span><span class="sxs-lookup"><span data-stu-id="d44b5-132">The following diagram shows a histogram that plots a predictable column, Bike Buyers, against an input column, Age.</span></span> <span data-ttu-id="d44b5-133">该柱状图显示了客户的年龄可帮助判断该客户是否将会购买自行车。</span><span class="sxs-lookup"><span data-stu-id="d44b5-133">The histogram shows that the age of a person helps distinguish whether that person will purchase a bicycle.</span></span>

 <span data-ttu-id="d44b5-134">![Microsoft 决策树算法中的直方图](../media/dt-histogram.gif "Microsoft 决策树算法中的直方图")</span><span class="sxs-lookup"><span data-stu-id="d44b5-134">![Histogram from Microsoft Decision Trees algorithm](../media/dt-histogram.gif "Histogram from Microsoft Decision Trees algorithm")</span></span>

 <span data-ttu-id="d44b5-135">该关系图中显示的关联将会使 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法在模型中创建一个新节点。</span><span class="sxs-lookup"><span data-stu-id="d44b5-135">The correlation that is shown in the diagram would cause the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm to create a new node in the model.</span></span>

 <span data-ttu-id="d44b5-136">![决策树节点](../media/dt-tree.gif "决策树节点")</span><span class="sxs-lookup"><span data-stu-id="d44b5-136">![Decision tree node](../media/dt-tree.gif "Decision tree node")</span></span>

 <span data-ttu-id="d44b5-137">随着算法不断向模型中添加新节点，便形成了树结构。</span><span class="sxs-lookup"><span data-stu-id="d44b5-137">As the algorithm adds new nodes to a model, a tree structure is formed.</span></span> <span data-ttu-id="d44b5-138">该树的顶端节点描述了客户总体可预测列的分解。</span><span class="sxs-lookup"><span data-stu-id="d44b5-138">The top node of the tree describes the breakdown of the predictable column for the overall population of customers.</span></span> <span data-ttu-id="d44b5-139">随着模型的不断增大，该算法将考虑所有列。</span><span class="sxs-lookup"><span data-stu-id="d44b5-139">As the model continues to grow, the algorithm considers all columns.</span></span>

### <a name="predicting-continuous-columns"></a><span data-ttu-id="d44b5-140">预测连续列</span><span class="sxs-lookup"><span data-stu-id="d44b5-140">Predicting Continuous Columns</span></span>
 <span data-ttu-id="d44b5-141">当 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 决策树算法根据可预测的连续列生成树时，每个节点都包含一个回归公式。</span><span class="sxs-lookup"><span data-stu-id="d44b5-141">When the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm builds a tree based on a continuous predictable column, each node contains a regression formula.</span></span> <span data-ttu-id="d44b5-142">拆分出现在回归公式的每个非线性点处。</span><span class="sxs-lookup"><span data-stu-id="d44b5-142">A split occurs at a point of non-linearity in the regression formula.</span></span> <span data-ttu-id="d44b5-143">例如，请看下面的关系图。</span><span class="sxs-lookup"><span data-stu-id="d44b5-143">For example, consider the following diagram.</span></span>

 <span data-ttu-id="d44b5-144">![显示非线性的多条回归线](../media/regression-tree1.gif "显示非线性的多条回归线")</span><span class="sxs-lookup"><span data-stu-id="d44b5-144">![Multiple regression lines showing non-linearity](../media/regression-tree1.gif "Multiple regression lines showing non-linearity")</span></span>

 <span data-ttu-id="d44b5-145">该关系图包含可通过使用一条或两条连线建模的数据。</span><span class="sxs-lookup"><span data-stu-id="d44b5-145">The diagram contains data that can be modeled either by using a single line or by using two connected lines.</span></span> <span data-ttu-id="d44b5-146">不过，一条连线将使得模型表示数据的效果较差。</span><span class="sxs-lookup"><span data-stu-id="d44b5-146">However, a single line would do a poor job of representing the data.</span></span> <span data-ttu-id="d44b5-147">相反，如果使用两条连线，则模型可以更精确地逼近数据。</span><span class="sxs-lookup"><span data-stu-id="d44b5-147">Instead, if you use two lines, the model will do a much better job of approximating the data.</span></span> <span data-ttu-id="d44b5-148">两条连线的相交点是非线性点，并且是决策树模型中的节点将拆分的点。</span><span class="sxs-lookup"><span data-stu-id="d44b5-148">The point where the two lines come together is the point of non-linearity, and is the point where a node in a decision tree model would split.</span></span> <span data-ttu-id="d44b5-149">例如，与上图中的非线性点相对应的节点可以由以下关系图表示。</span><span class="sxs-lookup"><span data-stu-id="d44b5-149">For example, the node that corresponds to the point of non-linearity in the previous graph could be represented by the following diagram.</span></span> <span data-ttu-id="d44b5-150">两个等式表示两条连线的回归等式。</span><span class="sxs-lookup"><span data-stu-id="d44b5-150">The two equations represent the regression equations for the two lines.</span></span>

 <span data-ttu-id="d44b5-151">![表示非线性点的等式](../media/regression-tree2.gif "表示非线性点的等式")</span><span class="sxs-lookup"><span data-stu-id="d44b5-151">![Equation that represents a point of non-linearity](../media/regression-tree2.gif "Equation that represents a point of non-linearity")</span></span>

## <a name="data-required-for-decision-tree-models"></a><span data-ttu-id="d44b5-152">决策树模型所需的数据</span><span class="sxs-lookup"><span data-stu-id="d44b5-152">Data Required for Decision Tree Models</span></span>
 <span data-ttu-id="d44b5-153">在准备用于决策树模型的数据时，应了解特定算法的要求，其中包括所需的数据量以及数据的使用方式。</span><span class="sxs-lookup"><span data-stu-id="d44b5-153">When you prepare data for use in a decision trees model, you should understand the requirements for the particular algorithm, including how much data is needed, and how the data is used.</span></span>

 <span data-ttu-id="d44b5-154">决策树模型的要求如下：</span><span class="sxs-lookup"><span data-stu-id="d44b5-154">The requirements for a decision trees model are as follows:</span></span>

-   <span data-ttu-id="d44b5-155">**单键列** 每个模型都必须包含一个用于唯一标识每条记录的数值列或文本列。</span><span class="sxs-lookup"><span data-stu-id="d44b5-155">**A single key column** Each model must contain one numeric or text column that uniquely identifies each record.</span></span> <span data-ttu-id="d44b5-156">不允许复合键。</span><span class="sxs-lookup"><span data-stu-id="d44b5-156">Compound keys are not permitted.</span></span>

-   <span data-ttu-id="d44b5-157">**可预测列** 至少需要一个可预测列。</span><span class="sxs-lookup"><span data-stu-id="d44b5-157">**A predictable column** Requires at least one predictable column.</span></span> <span data-ttu-id="d44b5-158">可以在模型中包括多个可预测属性，并且这些可预测属性的类型可以不同，可以是数值型或离散型。</span><span class="sxs-lookup"><span data-stu-id="d44b5-158">You can include multiple predictable attributes in a model, and the predictable attributes can be of different types, either numeric or discrete.</span></span> <span data-ttu-id="d44b5-159">不过，增加可预测属性的数目可导致处理时间增加。</span><span class="sxs-lookup"><span data-stu-id="d44b5-159">However, increasing the number of predictable attributes can increase processing time.</span></span>

-   <span data-ttu-id="d44b5-160">**输入列** 需要输入列，可为离散型或连续型。</span><span class="sxs-lookup"><span data-stu-id="d44b5-160">**Input columns** Requires input columns, which can be discrete or continuous.</span></span> <span data-ttu-id="d44b5-161">增加输入属性的数目会影响处理时间。</span><span class="sxs-lookup"><span data-stu-id="d44b5-161">Increasing the number of input attributes affects processing time.</span></span>

 <span data-ttu-id="d44b5-162">有关决策树模型支持的内容类型和数据类型的更多详细信息，请参阅 [Microsoft 决策树算法技术参考](microsoft-decision-trees-algorithm-technical-reference.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-162">For more detailed information about the content types and data types supported for decision tree models, see the Requirements section of [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md).</span></span>

## <a name="viewing-a-decision-trees-model"></a><span data-ttu-id="d44b5-163">查看决策树模型</span><span class="sxs-lookup"><span data-stu-id="d44b5-163">Viewing a Decision Trees Model</span></span>
 <span data-ttu-id="d44b5-164">若要浏览该模型，可以使用 **“Microsoft 树查看器”**。</span><span class="sxs-lookup"><span data-stu-id="d44b5-164">To explore the model, you can use the **Microsoft Tree Viewer**.</span></span> <span data-ttu-id="d44b5-165">如果模型生成多个树，则可以选择其中一个树，然后该查看器即会显示对于每个可预测属性，这些事例分类方式的明细。</span><span class="sxs-lookup"><span data-stu-id="d44b5-165">If your model generates multiple trees, you can select a tree and the viewer shows you a breakdown of how the cases are categorized for each predictable attribute.</span></span> <span data-ttu-id="d44b5-166">还可以使用依赖关系网络查看器来查看这些树的交互。</span><span class="sxs-lookup"><span data-stu-id="d44b5-166">You can also view the interaction of the trees by using the dependency network viewer.</span></span> <span data-ttu-id="d44b5-167">有关详细信息，请参阅 [使用 Microsoft 树查看器浏览模型](browse-a-model-using-the-microsoft-tree-viewer.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-167">For more information, see [Browse a Model Using the Microsoft Tree Viewer](browse-a-model-using-the-microsoft-tree-viewer.md).</span></span>

 <span data-ttu-id="d44b5-168">如果想了解关于树中任何分支或节点的更多详细信息，还可以使用 [Microsoft 一般内容树查看器](browse-a-model-using-the-microsoft-generic-content-tree-viewer.md)浏览该模型。</span><span class="sxs-lookup"><span data-stu-id="d44b5-168">If you want to know more detail about any branch or node in the tree, you can also browse the model by using the [Microsoft Generic Content Tree Viewer](browse-a-model-using-the-microsoft-generic-content-tree-viewer.md).</span></span> <span data-ttu-id="d44b5-169">为该模型存储的内容包括每个节点中所有值的分布、树中每一级别的概率和连续属性的回归公式。</span><span class="sxs-lookup"><span data-stu-id="d44b5-169">The content stored for the model includes the distribution for all values in each node, probabilities at each level of the tree, and regression formulas for continuous attributes.</span></span> <span data-ttu-id="d44b5-170">有关详细信息，请参阅 [决策树模型的挖掘模型内容（Analysis Services - 数据挖掘）](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-170">For more information, see [Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md).</span></span>

## <a name="creating-predictions"></a><span data-ttu-id="d44b5-171">创建预测</span><span class="sxs-lookup"><span data-stu-id="d44b5-171">Creating Predictions</span></span>
 <span data-ttu-id="d44b5-172">处理过模型之后，结果将以一组模式和统计信息的形式存储，可以使用这些结果来研究关系或作出预测。</span><span class="sxs-lookup"><span data-stu-id="d44b5-172">After the model has been processed, the results are stored as a set of patterns and statistics, which you can use to explore relationships or make predictions.</span></span>

 <span data-ttu-id="d44b5-173">有关用于决策树模型的查询的示例，请参阅 [决策树模型查询示例](decision-trees-model-query-examples.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-173">For examples of queries to use with a decision trees model, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>

 <span data-ttu-id="d44b5-174">有关如何创建针对挖掘模型的查询的常规信息，请参阅 [数据挖掘查询](data-mining-queries.md)。</span><span class="sxs-lookup"><span data-stu-id="d44b5-174">For general information about how to create queries against mining models, see [Data Mining Queries](data-mining-queries.md).</span></span>

## <a name="remarks"></a><span data-ttu-id="d44b5-175">备注</span><span class="sxs-lookup"><span data-stu-id="d44b5-175">Remarks</span></span>

-   <span data-ttu-id="d44b5-176">支持使用预测模型标记语言 (PMML) 创建挖掘模型。</span><span class="sxs-lookup"><span data-stu-id="d44b5-176">Supports the use of Predictive Model Markup Language (PMML) to create mining models.</span></span>

-   <span data-ttu-id="d44b5-177">支持钻取。</span><span class="sxs-lookup"><span data-stu-id="d44b5-177">Supports drillthrough.</span></span>

-   <span data-ttu-id="d44b5-178">支持使用 OLAP 挖掘模型和创建数据挖掘维度。</span><span class="sxs-lookup"><span data-stu-id="d44b5-178">Supports the use of OLAP mining models and the creation of data mining dimensions.</span></span>

## <a name="see-also"></a><span data-ttu-id="d44b5-179">另请参阅</span><span class="sxs-lookup"><span data-stu-id="d44b5-179">See Also</span></span>
 <span data-ttu-id="d44b5-180">[数据挖掘算法 &#40;Analysis Services 数据挖掘&#41;](data-mining-algorithms-analysis-services-data-mining.md) [Microsoft 决策树算法技术参考](microsoft-decision-trees-algorithm-technical-reference.md)[决策树模型查询示例](decision-trees-model-query-examples.md)[决策树模型的挖掘模型内容 &#40;Analysis Services 数据挖掘&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)</span><span class="sxs-lookup"><span data-stu-id="d44b5-180">[Data Mining Algorithms &#40;Analysis Services - Data Mining&#41;](data-mining-algorithms-analysis-services-data-mining.md) [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md) [Decision Trees Model Query Examples](decision-trees-model-query-examples.md) [Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)</span></span>


